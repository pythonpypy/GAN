{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input,Conv2D,Dropout,Dense,Flatten,BatchNormalization\n",
    "from keras.layers import Conv2DTranspose,UpSampling2D,Reshape,Activation\n",
    "from keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_images = r\"C:\\Users\\Munna chowhan\\apple.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(input_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data / 255\n",
    "data = np.reshape(data,(data.shape[0], 28, 28 , 1))\n",
    "img_w, img_h = data.shape[1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.imshow(data[4343,:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator(num_of_neurons = 64,drop_out = 0.4):\n",
    "    \n",
    "    #input layer:\n",
    "    input_layer = Input(shape=(img_w,img_h,1))\n",
    "    \n",
    "    conv_layer_1 = Conv2D(num_of_neurons * 1, 5,strides= 2, activation=\"relu\", padding=\"same\")(input_layer)\n",
    "    conv_layer_1 = Dropout(drop_out)(conv_layer_1)\n",
    "    \n",
    "    conv_layer_2 = Conv2D(num_of_neurons * 2, 5, strides=2, activation=\"relu\", padding=\"same\")(conv_layer_1)\n",
    "    conv_layer_2 = Dropout(drop_out)(conv_layer_2)\n",
    "    \n",
    "    conv_layer_3 = Conv2D(num_of_neurons * 4, 5,strides= 2, activation=\"relu\", padding=\"same\")(conv_layer_2)\n",
    "    conv_layer_3 = Dropout(drop_out)(conv_layer_3)\n",
    "    \n",
    "    conv_layer_4 = Conv2D(num_of_neurons * 8, 5,strides= 1, activation=\"relu\", padding=\"same\")(conv_layer_3)\n",
    "    conv_layer_4 = Flatten() (Dropout(drop_out)(conv_layer_4))\n",
    "    \n",
    "    #output layer:\n",
    "    output_layer = Dense(units=1,activation=\"sigmoid\")(conv_layer_4)\n",
    "    \n",
    "    model = Model(input_layer, output_layer)\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = build_discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.compile(optimizer=RMSprop(lr = 0.0008,decay=6e-8 ,clipvalue = 1.0 ), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator(laten_space_dim = 100, filters = 64, drop_out = 0.4):\n",
    "    \n",
    "    #input layer:\n",
    "    input_layer = Input((laten_space_dim,))\n",
    "    \n",
    "    #Dense layer:\n",
    "    dense_layer = Dense(units=7*7*filters)(input_layer)\n",
    "    dense_layer = BatchNormalization(momentum=0.9)(dense_layer)\n",
    "    dense_layer = Activation(activation=\"relu\")(dense_layer)\n",
    "    dense_layer = Reshape(target_shape=(7,7,64))(dense_layer)\n",
    "    dense_layer = Dropout(drop_out)(dense_layer)\n",
    "    \n",
    "    #Deconv layer:\n",
    "    # upsample is used to increase the size from (7,7) -- >(28,28)\n",
    "    de_conv_layer_1 = UpSampling2D()(dense_layer)\n",
    "    de_conv_layer_1 = Conv2DTranspose(filters=int(filters/2), kernel_size=5, padding=\"same\", activation=None)(de_conv_layer_1)\n",
    "    de_conv_layer_1 = BatchNormalization(momentum=0.9)(de_conv_layer_1)\n",
    "    de_conv_layer_1 = Activation(activation=\"relu\")(de_conv_layer_1)\n",
    "    \n",
    "    de_conv_layer_2 = UpSampling2D()(de_conv_layer_1)\n",
    "    de_conv_layer_2 = Conv2DTranspose(filters=int(filters/4), kernel_size=5, padding=\"same\", activation=None)(de_conv_layer_2)\n",
    "    de_conv_layer_2 = BatchNormalization(momentum=0.9)(de_conv_layer_2)\n",
    "    de_conv_layer_2 = Activation(activation=\"relu\")(de_conv_layer_2)\n",
    "    \n",
    "\n",
    "    de_conv_layer_3 = Conv2DTranspose(filters=int(filters/8), kernel_size=5, padding=\"same\", activation=None)(de_conv_layer_2)\n",
    "    de_conv_layer_3 = BatchNormalization(momentum=0.9)(de_conv_layer_3)\n",
    "    de_conv_layer_3 = Activation(activation=\"relu\")(de_conv_layer_3)\n",
    "    \n",
    "    #combine all the filters to make it in to one single image \n",
    "    output_layer = Conv2D(filters=1,kernel_size=5, padding=\"same\",activation=\"sigmoid\")(de_conv_layer_3)\n",
    "    \n",
    "    model = Model(input_layer, output_layer)\n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = build_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_adversarial(laten_space_dim = 100):\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(generator)\n",
    "    model.add(discriminator)\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer = RMSprop(lr = 0.0004, decay = 3e-8, clipvalue =1.0), metrics = [\"accuracy\"])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adversarial_network = build_adversarial()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_trainable(network, value):\n",
    "    network.trainable = value\n",
    "    for layer in network.layers:\n",
    "        layer.trainable = value\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs = 2000, batch_size = 128):\n",
    "    \n",
    "    \n",
    "    d_metrics = []\n",
    "    a_metrics = []\n",
    "    \n",
    "    running_d_loss = 0\n",
    "    running_d_acc = 0\n",
    "    \n",
    "    running_a_loss = 0\n",
    "    running_a_acc = 0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print(\"Epoch: {} \".format(epoch + 1))\n",
    "    \n",
    "        # take real and fake images to feed in to discriminator\n",
    "        real_imgs = np.reshape(data[np.random.choice(data.shape[0],size= batch_size,replace=False)], (batch_size,28,28,1))\n",
    "        fake_imgs = generator.predict(np.random.uniform(-1.0,1.0,size=(batch_size, 100)))#predict 128 images from 100 dim latent space\n",
    "        #(random noise)\n",
    "        \n",
    "        #concatenate both the images\n",
    "        x = np.concatenate((real_imgs, fake_imgs))\n",
    "        #2d array containing ones\n",
    "        y = np.ones([batch_size*2,1])\n",
    "        # label second half of y to have 0 \n",
    "        y[batch_size:,:] = 0\n",
    "        \n",
    "        # make the discriminator network trainable to first classify fake and real images\n",
    "        make_trainable(discriminator, True)\n",
    "         # we have to compile the after changing the trainable parameter\n",
    "        discriminator.compile(optimizer=RMSprop(lr = 0.0008,decay=6e-8 ,clipvalue = 1.0 ), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "        #train on that single batch and get metrics\n",
    "        d_metrics.append(discriminator.train_on_batch(x, y))\n",
    "        # get loss \n",
    "        running_d_loss += d_metrics[-1][0]\n",
    "        # get acc\n",
    "        running_d_acc += d_metrics[-1][1]\n",
    "        # make the discriminator freeze to train generator\n",
    "        make_trainable(discriminator, False)\n",
    "         # we have to re - compile the after changing the trainable parameter\n",
    "        discriminator.compile(optimizer=RMSprop(lr = 0.0008,decay=6e-8 ,clipvalue = 1.0 ), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "        # feed noise into generator\n",
    "        noise = np.random.uniform(-1.0,1.0,size=(batch_size, 100))\n",
    "        # feeding the noise images with labels as 1 to trick the discriminator and generate real looking images by updating the loss on noise images compared to the real images\n",
    "\n",
    "        y = np.ones([batch_size,1])\n",
    "        # train on the batch and get metrics\n",
    "        a_metrics.append(adversarial_network.train_on_batch(noise, y))\n",
    "        # get loss\n",
    "        running_a_loss += a_metrics[-1][0]\n",
    "        #get accuracy\n",
    "        running_a_acc += a_metrics[-1][1]\n",
    "        \n",
    "        if (epoch + 1) % 500 == 0:\n",
    "            # displaying log metrics\n",
    "            print(\"Epoch: {} \".format(epoch + 1))\n",
    "            log_msg = \"%d: [D loss: %f, acc: %f]\" %(epoch,running_d_loss/epoch, running_d_acc / epoch)\n",
    "            log_msg = \"%s: [A loss: %f, acc: %f]\" %(log_msg, running_a_loss/epoch, running_a_acc/ epoch)\n",
    "            print(log_msg)\n",
    "            \n",
    "            # randomly generate 16 noise samples from 100 dim latent space\n",
    "            noise = np.random.uniform(-1.0,1.0,size=(16, 100))\n",
    "            #predict those 16 noise data\n",
    "            predicted_imgs = generator.predict(noise)\n",
    "            \n",
    "            #plotting \n",
    "            plt.figure(figsize=(8,8))\n",
    "            # loop through all the images\n",
    "            for img in range(predicted_imgs.shape[0]):\n",
    "                \n",
    "                plt.subplot(4,4, img + 1)\n",
    "                plt.imshow(predicted_imgs[img,:,:,0], cmap=\"gray\")\n",
    "                plt.axis(\"off\")\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "    return a_metrics, d_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_metrics, d_metrics = train(epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = pd.DataFrame( {\"Discriminator Loss\": [metric[0] for metric in d_metrics],\n",
    "                      \"Generator Loss\": [metric[0] for metric in a_metrics]}).plot(title=\"Training loss\",logy=True)\n",
    "loss.set_xlabel(\"Epochs\")\n",
    "loss.set_ylabel(\"Loss\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = pd.DataFrame( {\"Discriminator Accuracy\": [metric[1] for metric in d_metrics],\n",
    "                      \"Generator Accuracy\": [metric[1] for metric in a_metrics]}).plot(title=\"Training accuracy\")\n",
    "accuracy.set_xlabel(\"Epochs\")\n",
    "accuracy.set_ylabel(\"Accuracy\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
